# 7. 합성곱 신경망 (CNN)

* 합성곱 신경망 (Convolutional Neural Network)
    - 이미지 인식과 음성 인식 등 다양한 곳에서 사용
    - 특히 이미지 인식 분야에서 딥러닝을 활용한 기법은 거의 CNN 을 기초로 함
    - CNN 메커니즘을 설명하고, 파이썬으로 구현함

## 7.1 전체 구조

* CNN 네트워크 구조
    - 지금까지의 신경망과 같이 레고 블럭 처럼 계층을 조합하여 만듦
    - 합성곱 계층 (convolutional layer) 과 풀링 계층 (pooling layer) 가 새롭게 등장함

* 완전 연결 신경망
    - 지금까지의 신경망 : 인접하는 계층의 모든 뉴런과 결합함
    - 완전 연결 (fully-connected) : Affine 계층이라는 이름으로 구현
    - 완전 연결 신경망 : Affine 계층 뒤에 ReLU 계층 (또는 Sigmoid 계층) 이 이어짐
    - 그림 7-1 : 5-층 신경망 - Affine-ReLU 조합 4개 쌓고, 마지막 층은 Affine-Softmax 임

* CNN 구조
    - '합성곱 계층 (Conv)' 과 '풀링 계층 (Pooling)' 추가
    - CNN 계층 : Conv-ReLU-(Pooling) 으로 연결 (풀링 계층은 생략 가능)
    - Affine-ReLU 가 Conv-ReLU-(Pooling) 으로 바뀐 형태
    - 그림 7-2 : 일반적인 5-층 CNN - 출력에 가까운 층은 Affine-ReLU, 마지막 층은 Affine-Softmax 그대로 사용

## 7.2 합성곱 계층

* CNN 과 완전 연결 신경망 차이점
    - '패딩 (padding)', '스트라이드 (보폭, stride)' 등 CNN 고유 용어 등장
    - 계층 간에 3차원 데이터 같은 입체적인 데이터가 흐름

* CNN 에서 사용하는 합성곱 계층의 구조를 살펴봄

### 7.2.1 완전 연결 계층의 문제점

* 완전 연결 계층
    - 완전 연결 신경망에서 사용
    - 인접하는 계층의 뉴런을 모두 연결하고 출력의 수는 임의로 정함

* 완전 연결 계층의 문제점
    - 데이터의 형상을 무시함
    - 이미지의 경우 세로, 가로, 채널로 구성된 3차원 데이터이지만, 완전 연결 계층에 입력할 때는 이를 평평한 1차원 데이터로 바꿔줌
    - MNIST 데이터셋 예제에서도 (채널 1, 가로 28, 세로 28) 인 이미지를 784개의 데이터로 Affine 계층에 입력함
    - 이미지는 3차원 형상이며, , 소중한 공간적 정보가 담겨 있음
    - 가까운 픽셀은 비슷하고, RGB 채널사이의 관계는 밀접하며, 먼 픽셀은 관련이 없는 등, 3차원 속에서 의미를 갖는 본질적인 패턴이 있을 것임
    - 완전 연결 계층은 형상을 무시하고 모든 입력 데이터를 동등한 (차원의) 뉴런으로 취급하여 형상에 담긴 정보를 살릴 수 없음

* 합성곱 계층
    - 형상을 유지함
    - 이미지도 3차원 데이터로 입력받으며, 다음 계층에도 3차원 데이터로 전달함
    - 그래서 CNN 은 이미지 처럼 형상을 가진 데이터를 제대로 이해할 (가능성이 있을) 수 있음

* 특징 맵 (feature map)
    - CNN 합성곱 계층의 입출력 데이터
    - 입력 특징 맵 (input feature map) : 합성곱 계층의 입력 데이터
    - 출력 특징 맵 (output feature map) : 합성곱 계층의 출력 데이터
    - 이 책에서는 '입출력 데이터' 와 '특징 맵' 을 같은 의미로 사용

### 7.2.2 합성곱 연산

* 합성곱 연산
    - 합성곱 계층에서는 합성곱 연산을 처리함
    - 이미지 처리에서 말하는 '필터 연산' 에 해당함
    - 그림 7-3 : 합성곱 연산은 입력 데이터에 필터를 적용함
    - 입력 데이터는 세로, 가로 방향의 형상을 가짐, 필터 역시 세로, 가로 방향의 차원을 가짐
    - 데이터와 필터의 형상은 (높이-height, 너비-width) 로 표기
    - 문헌에 따라 '필터' 를 '커널' 이라 하기도 함

* 합성곱 연산의 계산 순서
    - 그림 7-4
    - 합성곱 연산은 필터의 '윈도우 (window)' 를 일정 간격으로 이동하면서 입력 데이터에 적용함
    - 윈도우는 이미지에서 필터가 적용되는 부분-회색 부분-을 말함
    - 단일 곱셈-누산 (Fused Multiply-Add) : 입력과 필터에서 서로 대응하는 원소끼리 곱한 후 총합을 구함
    - 결과를 출력의 해당 장소에 저장
    - 모든 장소에서 수행하면 합성곱 연산의 출력 완성

* 가중치 매개 변수와 편향
    - 완전 연결 신경망에서는 가중치 매개 변수와 편향 존재
    - CNN 에서는 '필터의 매개 변수' 가 '가중치' 에 해당함
    - CNN 에도 편향 존재 : 그림 7-3 은 필터 적용 단계까지만 보인 것
    - 그림 7-5 : 편향까지 포함한 흐름 - 편향은 필터를 적용한 후의 데이터에 더함
    - 편향은 항상 하나 (1, 1) 만 존재 : 이 하나의 값을 필터를 적용한 모든 원소에 더함

### 7.2.3 패딩

* 패딩 (padding)
    - 합성곱 연산을 수행하기 전에 입력 데이터 주변을 (0 같은) '특정 값' 으로 채우는 것
    - 합성곱 연산에서 자주 사용하는 기법
    - 그림 7-6 : (4, 4) 크기의 입력 데이터에 폭이 1인 패팅을 적용한 모습
    - 처음에 크기가 (4, 4) 인 입력 데이터에 패딩을 추가하여 (6, 6) 이 됨
    - 이 입력에 (3, 3) 크기의 필터를 걸면 (4, 4) 크기의 출력 데이터를 생성함
    - 패딩은 1 외에도 2 나 3 등 원하는 정수로 설정할 수 있음
    - 그림 7-5 에 패딩을 2로 설정하면 입력 데이터의 크기는 (8, 8), 3으로 설정하면 (10, 10) 이 됨

> 패딩은 주로 출력 크기를 조정할 목적으로 사용함
> 예를 들어, (4, 4) 입력 데이터에 (3, 3) 필터를 적용하면 출력은 (2, 2) 가 되어, 입력보다 2만큼 줄어듦
> 합성곱 연산을 되풀이하는 심층 신경망에서는 문제가 될 수 있음
> 합성곱 연산을 거칠 때마다 크기가 작아져서 어느 시점에 출력 크기가 1이 되면 더 이상 합성곱 연산을 적용할 수 없게됨
> 이를 막기 위해 패딩 사용
> 패딩 폭을 1로 설명하면 (4, 4) 입력에 대한 출력이 (4, 4) 로 유지됨
> 입력 데이터의 크기를 고정한 채로 다음 계층에 전달할 수 있음

### 7.2.4 스트라이드

* 스트라이드 (stride)
    - 필터를 적용하는 위치의 간격
    - 스트라이드를 2로 하면 필터를 적용하는 윈도우가 두 칸씩 이동함
    - 그림 7-7 : 크기가 (7, 7) 인 입력 데이터에 스트라이드를 2로 설정한 필터 적용
    - 스트라이트를 2로 하니 출력이 (3, 3) 이 됨

* 출력 크기
    - 스트라이드를 키우면 출력 크기는 작아짐
    - 패딩을 크게 하면 출력 크기가 커짐
    - 입력 크기 : (H, W)
    - 필터 크기 : (FH, FW)
    - 출력 크기 : (OH, OW)
    - 패딩 : P
    - 스트라이드 : S
    - 식 7-1
    - <img src="https://latex.codecogs.com/svg.latex?OH&space;=&space;\frac{H&plus;2P-FH}{S}&space;&plus;&space;1" title="OH = \frac{H+2P-FH}{S} + 1" />
    - <img src="https://latex.codecogs.com/svg.latex?OW&space;=&space;\frac{W&plus;2P-FW}{S}&space;&plus;&space;1" title="OW = \frac{W+2P-FW}{S} + 1" />

* 예제
    - 입력 (4, 4), 패딩 1, 스트라이드 1, 필터 (3, 3) 
    - <img src="https://latex.codecogs.com/svg.latex?OH&space;=&space;\frac{4&plus;2\cdot&space;1-3}{1}&space;&plus;&space;1=4" title="OH = \frac{4+2\cdot 1-3}{1} + 1=4" />
    - <img src="https://latex.codecogs.com/svg.latex?OW&space;=&space;\frac{4&plus;2\cdot&space;1-3}{1}&space;&plus;&space;1=4" title="OW = \frac{4+2\cdot 1-3}{1} + 1=4" />
    - 입력 (7, 7), 패딩 0, 스트라이드 2, 필터 (3, 3) 
    - <img src="https://latex.codecogs.com/svg.latex?OH&space;=&space;\frac{7&plus;2\cdot&space;0-3}{2}&space;&plus;&space;1=3" title="OH = \frac{7+2\cdot 0-3}{2} + 1=3" />
    - <img src="https://latex.codecogs.com/svg.latex?OW&space;=&space;\frac{7&plus;2\cdot&space;0-3}{2}&space;&plus;&space;1=3" title="OH = \frac{7+2\cdot 0-3}{2} + 1=3" />
    - 입력 (28, 31), 패딩 2, 스트라이드 3, 필터 (5, 5) 
    - <img src="https://latex.codecogs.com/svg.latex?OH&space;=&space;\frac{28&plus;2\cdot&space;2-5}{3}&space;&plus;&space;1=10" title="OH = \frac{28+2\cdot 2-5}{3} + 1=10" />
    - <img src="https://latex.codecogs.com/svg.latex?OW&space;=&space;\frac{31&plus;2\cdot&space;2-5}{3}&space;&plus;&space;1=11" title="OH = \frac{31+2\cdot 2-5}{3} + 1=11" />
    - 식 7-1 에 값을 단순히 대입하면 출력 크기를 구할 수 있음
    - 단 식에서 분수식이 정수로 나눠 떨어지는 값이어야 함 : 출력 크기가 정수가 아니면 오류를 발생하는 등의 대응을 해줘야 함
    - 딥러닝 프레임웍 중에는 값이 나눠 떨어지지 않을 경우 가장 가까운 정수로 반올림 하는 등, 에러 없이 진행하도록 구현하는 경우도 있음

### 7.2.5 3차원 데이터의 합성곱 연산

* 3차원 데이터
    - 지금까지 2차원 형상을 다루는 합성곱 연산을 살펴봄
    - 이미지도 세로, 가로, 채널까지 3차원 데이터임
    - 채널까지 고려한 3차원 데이터를 다루는 합성곱 연산을 살펴봄

* 3차원 데이터의 합성곱 연산 예
    - 그림 7-8
    - 2차원일 때와 비교하여, 채널 방향으로 특징 맵이 늘어남

* 3차원 데이터의 합성곱 연산 순서
    - 그림 7-9
    - 채널 방향으로 특징 맵이 여러 개가 있으면 입력 데이터와 필터의 합성곱 연산을 채널마다 수행하고, 그 결과를 더해서 하나의 출력으로 얻음     

* 주의할 점
    - 3차원 합성곱 연산에서 입력 데이터 채널 수와 필터의 채널 수가 같아야 함
    - 그림 7-8, 7-9 에서는 모두 3개로 일치함
    - 필터 자체의 크기는 원하는 값으로 설정할 수 있음 : 단, 모든 채널의 필터는 같은 크기여야 함
    - 그림 7-8, 7-9 에서는 필터 크기가 (3, 3) 이지만, (2, 2) , (1, 1), 또는 (5, 5) 등도 가능함

### 7.2.6 블럭으로 생각하기

* 블럭
    - 3차원 합성곱 연산은 데이터와 필터를 직육면체 블럭으로 생각하면 쉬움
    - 그림 7-10 : 블럭 - 3차원 직육면체
    - 3차원 데이터를 다차원 배열로 나타낼 때는 (채널 channel, 높이 height, 너비 width) 순서로 씀
    - (C, H, W) : 채널 수 C, 높이 H, 너비 W 인 데이터 형상 
    - 필터도 같은 순서임
    - (C, FH, FW) : 채널 수 C, 필터 높이 H, 필터 너비 W

* 출력 데이터
    - '츨력 데이터' 는 한 장의 '특징 맵' : 채널이 1개인 특징 맵
    - (C, H, W) * (C, FH, FW) → (1, OH, OW)
    
* 필터의 개수
    - 합성곱 연산의 출력으로 다수의 채널을 내보내려면, '필터 (가중치)' 를 다수 사용하면 됨
    - 그림 7-11
    - 필터를 FN 개 사용하면, 출력 맵도 FN 개가 생성됨
    - FN 개의 맵을 모으면 형상이 (FN, OH, OW) 인 블럭이 완성됨
    - 이 완성된 블럭을 다음 계층으로 넘기겠다는 것이 'CNN 의 처리 흐름' 임

* 4차원 데이터
    - 합성곱 연산에서는 필터의 개수도 고려해야 함
    - 따라서 '필터의 가중치 데이터' 는 4차원 데이터이며 (출력 채널 수, 입력 채널 수, 높이, 너비) 순서로 씀
    - 채널 수 3, 크기 5x5 인 필터가 20개 면, (20, 3, 5, 5)
    - 사실 (필터 개수, 채널 개수, 높이, 너비) 가 아닐까?

* 편향 
    - 합성곱 연산에도 (완전 연결 계층 처럼) 편향을 씀
    - 그림 7-12 : 그림 7-11 에 편향을 더한 모습
    - 편향은 채널 하나에 값 하나씩으로 구성됨
    - 여기서는 편향 형상이 (FN, 1, 1) 이고, 필터의 출력 형상은 (FN, OH, OW) 임
    - 이 두 블럭을 더하면 편향의 각 값이 필터 출력인 (FN, OH, OW) 블럭의 대응 채널 모든 원소에 더해짐
    - 형상이 다른 블럭의 덧셈은 NumPy 의 브로드캐스트 기능으로 쉽게 구현 가능함 (1.5.5 브로드캐스트 참고)

### 7.2.7 배치 처리

* 신경망 처리의 배치
    - 신경망 처리에서는 입력 데이터를 한 덩어리로 묶어서 배치로 처리함
    - 완전 연결 신경망 구현에서는 이 방식을 지원하여 처리 효율을 높이고, 미니 배치 방식의 학습도 지원함

* 합성곱 연산의 배치
    - 합성곱 연산도 배치 처리를 지원하려고 함
    - 각 계층을 흐르는 데이터의 차원을 하나 늘려 4차원 데이터로 저장함
    - 데이터를 (데이터 수, 채널 수, 높이, 너비) 순으로 저장

* 합성곱 연산의 배치 처리 흐름
    - 그림 7-13 : 데이터가 N 개일 때, 그림 7-12 배치 처리 시의 데이터 흐름
    - 각 데이터의 선두에 배치용 차원을 추가함
    - 데이터는 4차원 형상을 가지고 각 계층을 타고 흐름
    - 신경망에 4차원 데이터가 하나 흐를 떄마다 데이터 N 개에 대한 합성곱 연산이 이뤄짐 : N 회분의 처리를 한 번에 수행

## 7.3 풀링 계층

* 풀링 (pooling)
    - 세로, 가로 방향의 공간을 줄이는 연산
    - 그림 7-14 : 2x2 영역을 원소 하나로 집약하여 공간 크기를 줄임, '2x2 최대 풀링' 을 스트라이드 2 로 처리하는 순서
    - 2x2 최대 풀링 (max pooling) : 2x2 영역에서 가장 큰 원소를 하나 꺼내는 것
    - 풀링의 윈도우 크기와 스트라이드는 같은 값으로 설정하는 것이 일반적임

> 평균 풀링 (average pooling) : 대상 영역의 평균을 계산함
>
> 이미지 인식 분야에서는 주로 최대 풀링을 사용함 : 이 책의 풀링 계층도 '최대 풀링' 을 의미함

### 7.3.1 풀링 계층의 특징

1. 학습해야 할 매개 변수가 없다
    - 풀링 계층은 합성곱 계층과 달리 학습해야 할 매개 변수가 없음
    - 풀링은 대상 영역에서 최대값 또는 평균을 취하는 명확한 처리이므로 특별히 학습할 것이 없음

2. 채널 수가 변하지 않는다
    - 풀링 연산은 입력 데이터의 채널 수 그대로 출력 데이터로 내보냄 : 채널마다 독립적으로 계산하기 때문
    - 그림 7-15

3. 입력의 변화에 영향을 적게 받는다 (강건함)
    - 입력 데이터가 조금 변해도 풀링의 결과는 잘 변하지 않음
    - 7-16 : (데이터를 오른쪽으로 1칸 이동하는) 입력 데이터의 차이를 풀링이 흡수하여 사라지게 하는 모습

## 7.4 합성곱/풀링 계층 구현하기

* 합성곱 계층과 풀링 계층을 파이썬으로 구현
    - 5장 오차 역전파법 처럼, 이번 절에서 구현하는 class 에도 `forward` 와 `backward` 메소드를 추가하여 모듈로 이용 가능하도록 함
    - 합성곱 계층과 풀링 계층을 '트릭' 을 사용하여 쉽게 구현하도록 함

### 7.4.1 4차원 배열

### 7.4.2 im2col 로 데이터 전개하기

### 7.4.3 합성곱 계층 구현하기

### 7.4.4 풀링 계층 구현하기
